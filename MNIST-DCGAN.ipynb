{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:100: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3920, kernel_initializer=\"glorot_normal\")`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:105: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3920)              395920    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 3920)              15680     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3920)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 20, 14, 14)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 40, 28, 14)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 40, 28, 10)        1270      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 40, 28, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 40, 28, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 40, 28, 5)         455       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 40, 28, 5)         20        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 40, 28, 5)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 40, 28, 1)         6         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 40, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 413,391\n",
      "Trainable params: 405,521\n",
      "Non-trainable params: 7,870\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(5, (3, 3), padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:111: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (1, 1), padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 5488)              554288    \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 7, 7, 112)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 7, 7, 112)         448       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 7, 7, 112)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 56)        156856    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 14, 14, 56)        224       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 14, 14, 56)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 1)         1401      \n",
      "=================================================================\n",
      "Total params: 713,217\n",
      "Trainable params: 712,881\n",
      "Non-trainable params: 336\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 56)        1456      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 112)         156912    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 224)         627424    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3584)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 112)               401520    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 113       \n",
      "=================================================================\n",
      "Total params: 1,187,425\n",
      "Trainable params: 1,187,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 28, 28, 1)         713221    \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 1)                 1187425   \n",
      "=================================================================\n",
      "Total params: 1,900,646\n",
      "Trainable params: 712,883\n",
      "Non-trainable params: 1,187,763\n",
      "_________________________________________________________________\n",
      "Epochs: 100\n",
      "Batch size: 128\n",
      "Batches per epoch: 234\n",
      "--------------- Epoch 1 ---------------\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 4800x800 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Epoch 20 ---------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 4800x800 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Epoch 40 ---------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 4800x800 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Epoch 60 ---------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 4800x800 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Epoch 80 ---------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 4800x800 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Epoch 100 ---------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 4800x800 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21947367\n",
      "2.2099333\n",
      "1.9657617\n",
      "2.2347536\n",
      "3.0332317\n",
      "1.5554779\n",
      "2.7389483\n",
      "2.2655706\n",
      "2.1191728\n",
      "0.12164329\n",
      "5.184205\n",
      "3.3913941\n",
      "3.730428\n",
      "2.9470592\n",
      "2.626609\n",
      "5.7663183\n",
      "5.310171\n",
      "3.4422255\n",
      "4.528407\n",
      "3.7213264\n",
      "3.4029503\n",
      "4.273555\n",
      "4.4913564\n",
      "4.047659\n",
      "5.3901815\n",
      "4.9366674\n",
      "3.039713\n",
      "4.130025\n",
      "6.386145\n",
      "6.10254\n",
      "4.693818\n",
      "4.6849194\n",
      "3.3748794\n",
      "5.40598\n",
      "5.6892343\n",
      "5.846978\n",
      "3.4558718\n",
      "4.1116705\n",
      "2.9341354\n",
      "4.169352\n",
      "2.9654279\n",
      "4.9349995\n",
      "3.8570287\n",
      "4.5140715\n",
      "3.73435\n",
      "3.18419\n",
      "0.87441695\n",
      "7.2222013\n",
      "4.725458\n",
      "5.942849\n",
      "2.5818386\n",
      "6.745908\n",
      "9.833729\n",
      "4.1403728\n",
      "4.3995085\n",
      "7.33261\n",
      "4.7635612\n",
      "4.214726\n",
      "5.7064657\n",
      "7.061511\n",
      "3.7610378\n",
      "6.5488486\n",
      "4.2374206\n",
      "4.863924\n",
      "3.4175339\n",
      "3.055187\n",
      "2.6427145\n",
      "4.0265646\n",
      "4.160581\n",
      "4.106189\n",
      "5.0821333\n",
      "3.3812404\n",
      "4.3436985\n",
      "3.0634184\n",
      "2.7098231\n",
      "3.983679\n",
      "4.0525665\n",
      "4.768269\n",
      "4.631371\n",
      "5.384979\n",
      "4.1382456\n",
      "2.6217628\n",
      "3.2512994\n",
      "4.08603\n",
      "3.6184788\n",
      "1.7272719\n",
      "4.9316826\n",
      "4.55225\n",
      "4.4006753\n",
      "5.2230663\n",
      "3.8258533\n",
      "3.866734\n",
      "3.4940608\n",
      "5.2752967\n",
      "5.1341095\n",
      "2.1600192\n",
      "7.3129964\n",
      "4.5089917\n",
      "6.9468613\n",
      "3.3687146\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Activation, Flatten, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose, UpSampling2D, Convolution2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt2\n",
    "import random\n",
    "#from tqdm import tqdm_notebook\n",
    "import math\n",
    "from keras import layers\n",
    "\n",
    "import scipy as sp\n",
    "#from tqdm import tqdm_notebook\n",
    "from math import floor\n",
    "from numpy import ones\n",
    "from numpy import expand_dims\n",
    "from numpy import log\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import exp\n",
    "from numpy import resize\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    " \n",
    "# assumes images have the shape 299x299x3, pixels in [0,255]\n",
    "def scale_images(images, new_shape):\n",
    "    images_list = list()\n",
    "    for image in images:\n",
    "        # resize with nearest neighbor interpolation\n",
    "        new_image = resize(image, new_shape)\n",
    "        # store\n",
    "        images_list.append(new_image)\n",
    "    return np.asarray(images_list)\n",
    "def calculate_inception_score(images, n_split=10, eps=1E-16):\n",
    "    # load inception v3 model\n",
    "    model = InceptionV3()\n",
    "    # convert from uint8 to float32\n",
    "    processed = images.astype('float32')\n",
    "    # pre-process raw images for inception v3 model\n",
    "    processed = preprocess_input(processed)\n",
    "    # predict class probabilities for images\n",
    "    yhat = model.predict(processed)\n",
    "    # enumerate splits of images/predictions\n",
    "    scores = list()\n",
    "    n_part = floor(images.shape[0] / n_split)\n",
    "    for i in range(n_split):\n",
    "        # retrieve p(y|x)\n",
    "        ix_start, ix_end = i * n_part, i * n_part + n_part\n",
    "        p_yx = yhat[ix_start:ix_end]\n",
    "        # calculate p(y)\n",
    "        p_y = expand_dims(p_yx.mean(axis=0), 0)\n",
    "        # calculate KL divergence using log probabilities\n",
    "        kl_d = p_yx * (log(p_yx + eps) - log(p_y + eps))\n",
    "        # sum over classes\n",
    "        sum_kl_d = kl_d.sum(axis=1)\n",
    "        # average over images\n",
    "        avg_kl_d = mean(sum_kl_d)\n",
    "        # undo the log\n",
    "        is_score = exp(avg_kl_d)\n",
    "        # store\n",
    "        scores.append(is_score)\n",
    "    # average across images\n",
    "    is_avg, is_std = mean(scores), std(scores)\n",
    "    return is_avg, is_std\n",
    "# calculate frechet inception distance\n",
    "def get_fid(act1, act2):\n",
    "    # calculate mean and covariance statistics\n",
    "    mu1, sigma1 = act1.mean(axis=0), np.cov(act1, rowvar=False)\n",
    "    mu2, sigma2 = act2.mean(axis=0), np.cov(act2, rowvar=False)\n",
    "    # calculate sum squared difference between means\n",
    "    ssdiff = np.sum((mu1 - mu2)**2.0)\n",
    "    # calculate sqrt of product between cov\n",
    "    covmean = sp.linalg.sqrtm(sigma1.dot(sigma2))\n",
    "    # check and correct imaginary numbers from sqrt\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    # calculate score\n",
    "    fid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "    return fid\n",
    "# Dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images.\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "# print(X_train.shape)\n",
    "\n",
    "z_dim = 100\n",
    "\n",
    "X_train = X_train.reshape(60000, 28, 28, 1)\n",
    "X_test = X_test.reshape(10000, 28, 28, 1)\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "X_train = X_train[0:30000]\n",
    "\n",
    "nch = 20\n",
    "g_input = Input(shape=[100])\n",
    "H1 = Dense(nch * 14 * 14, init='glorot_normal')(g_input)\n",
    "H = BatchNormalization()(H1)\n",
    "H = Activation('relu')(H)\n",
    "H = Reshape([nch, 14, 14])(H)\n",
    "H = UpSampling2D(size=(2, 2))(H)\n",
    "H = Convolution2D(int(nch / 2), 3, 3, border_mode='same', init='glorot_uniform')(H)\n",
    "H = BatchNormalization()(H)\n",
    "H = Activation('relu')(H)\n",
    "H = Convolution2D(int(nch / 4), 3, 3, border_mode='same', init='glorot_uniform')(H)\n",
    "H = BatchNormalization()(H)\n",
    "H = Activation('relu')(H)\n",
    "H = Convolution2D(1, 1, 1, border_mode='same', init='glorot_uniform')(H)\n",
    "g_V = Activation('sigmoid')(H)\n",
    "generator = Model(g_input, g_V)\n",
    "generator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
    "generator.summary()\n",
    "\n",
    "# Generator\n",
    "adam = Adam(lr=0.0002, beta_1=0.5)\n",
    "\n",
    "g = Sequential()\n",
    "layer = g.add(Dense(7 * 7 * 112, input_dim=z_dim))\n",
    "g.add(Reshape((7, 7, 112)))\n",
    "g.add(BatchNormalization())\n",
    "g.add(Activation(LeakyReLU(alpha=0.2)))\n",
    "g.add(Conv2DTranspose(56, 5, strides=2, padding='same'))\n",
    "g.add(BatchNormalization())\n",
    "g.add(Activation(LeakyReLU(alpha=0.2)))\n",
    "g.add(Conv2DTranspose(1, 5, strides=2, padding='same', activation='sigmoid'))\n",
    "g.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "g.summary()\n",
    "\n",
    "d = Sequential()\n",
    "d.add(Conv2D(56, 5, strides=2, padding='same', input_shape=(28, 28, 1), activation=LeakyReLU(alpha=0.2)))\n",
    "d.add(Conv2D(112, 5, strides=2, padding='same'))\n",
    "g.add(BatchNormalization())\n",
    "g.add(Activation(LeakyReLU(alpha=0.2)))\n",
    "d.add(Conv2D(224, 5, strides=2, padding='same'))\n",
    "g.add(Activation(LeakyReLU(alpha=0.2)))\n",
    "d.add(Flatten())\n",
    "d.add(Dense(112, activation=LeakyReLU(alpha=0.2)))\n",
    "d.add(Dense(1, activation='sigmoid'))\n",
    "d.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "d.summary()\n",
    "\n",
    "d.trainable = False\n",
    "inputs = Input(shape=(z_dim,))\n",
    "hidden = g(inputs)\n",
    "output = d(hidden)\n",
    "gan = Model(inputs, output)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "gan.summary()\n",
    "\n",
    "\n",
    "def plot_loss(losses):\n",
    "    \"\"\"\n",
    "    @losses.keys():\n",
    "        0: loss\n",
    "        1: accuracy\n",
    "    \"\"\"\n",
    "    d_loss = [v[0] for v in losses[\"D\"]]\n",
    "    g_loss = [v[0] for v in losses[\"G\"]]\n",
    "\n",
    "    plt.figure(figsize=(6.4, 4.8))\n",
    "    plt.plot(d_loss, color='red', label=\"Discriminator loss\")\n",
    "    plt.plot(g_loss, color='green', label=\"Generator loss\")\n",
    "    plt.title(\"GAN : MNIST dataset\")\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('loss.png')\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "def plot_generated(n_ex=20, dim=(2, 10), figsize=(48, 8)):\n",
    "    noise = np.random.normal(0, 1, size=(n_ex, z_dim))\n",
    "    generated_images = g.predict(noise)\n",
    "    generated_images = generated_images.reshape(generated_images.shape[0], 28, 28)\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i + 1)\n",
    "        # plt.imshow(generated_images[i, :, :], interpolation='nearest', cmap='gray_r')\n",
    "        sss = str(i)\n",
    "\n",
    "        plt.imsave(sss, generated_images[i, :, :], cmap='gray_r')\n",
    "\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.plot()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Set up a vector (dict) to store the losses\n",
    "losses = {\"D\": [], \"G\": []}\n",
    "samples = []\n",
    "\n",
    "\n",
    "mfid=[]\n",
    "def train(d, epochs=1, plt_frq=1, BATCH_SIZE=128):\n",
    "    batchCount = int(X_train.shape[0] / BATCH_SIZE)\n",
    "    #batchCount=100\n",
    "    print('Epochs:', epochs)\n",
    "    print('Batch size:', BATCH_SIZE)\n",
    "    print('Batches per epoch:', batchCount)\n",
    "\n",
    "    d_v = []\n",
    "    for e in range(1, epochs + 1):\n",
    "        if e == 1 or e % plt_frq == 0:\n",
    "            print('-' * 15, 'Epoch %d' % e, '-' * 15)\n",
    "        for _ in range(batchCount):  # tqdm_notebook(range(batchCount), leave=False):\n",
    "            # Create a batch by drawing random index numbers from the training set\n",
    "            image_batch = X_train[np.random.randint(0, X_train.shape[0], size=BATCH_SIZE)]\n",
    "            image_batch = image_batch.reshape(image_batch.shape[0], image_batch.shape[1], image_batch.shape[2], 1)\n",
    "            # print(image_batch.shape)\n",
    "            # Create noise vectors for the generator\n",
    "            noise = np.random.normal(0, 1, size=(BATCH_SIZE, z_dim))\n",
    "\n",
    "            # Generate the images from the noise\n",
    "            generated_images = g.predict(noise)\n",
    "            samples.append(generated_images)\n",
    "            X = np.concatenate((image_batch, generated_images))\n",
    "            # Create labels\n",
    "            y = np.zeros(2 * BATCH_SIZE)\n",
    "            y[:BATCH_SIZE] = 0.9  # One-sided label smoothing\n",
    "\n",
    "            # Train discriminator on generated images\n",
    "            d.trainable = True\n",
    "            d_loss = d.train_on_batch(X, y)\n",
    "            # Train generator\n",
    "            noise = np.random.normal(0, 1, size=(BATCH_SIZE, z_dim))\n",
    "            y2 = np.ones(BATCH_SIZE)\n",
    "            d.trainable = False\n",
    "            g_loss = gan.train_on_batch(noise, y2)\n",
    "            weights = []\n",
    "            ccc = 0\n",
    "\n",
    "        #weights = g.layers[0].get_weights()[0]\n",
    "        #w = 3\n",
    "        #weights = weights.reshape(548800)\n",
    "        #bin = [-0.08, -0.06, -0.04, -0.02, 0, 0.02, 0.04, 0.06, 0.08]\n",
    "\n",
    "        #px,py,_ = plt2.hist(weights, bins=100)\n",
    "        #print(str(np.argmax(px)) + '--' + str(np.max(py)))\n",
    "\n",
    "        sss = str(e)\n",
    "        # plt2.savefig(\"plt\" +sss +\".png\")\n",
    "        # plt2.clf()\n",
    "        #print(len(weights))\n",
    "\n",
    "        # Only store losses from final batch of epoch\n",
    "        #images1 = scale_images(generated_images, (299,299,3))\n",
    "        #print(calculate_inception_score(images1))\n",
    "        \n",
    "        \n",
    "        image_batch = image_batch.reshape(BATCH_SIZE,784)\n",
    "        generated_images = generated_images.reshape(BATCH_SIZE,784)\n",
    "        #print('fid : ' + str(get_fid(generated_images, image_batch)))\n",
    "        \n",
    "        mfid.append(get_fid(generated_images, image_batch))\n",
    "        losses[\"D\"].append(d_loss)\n",
    "        losses[\"G\"].append(g_loss)\n",
    "\n",
    "        # Update the plots\n",
    "        if e == 1 or e % plt_frq == 0:\n",
    "            plot_generated()\n",
    "    # print((weights.shape ))\n",
    "    \n",
    "\n",
    "    # for fff in range(0,100):\n",
    "    # print(losses[\"D\"][fff][0])\n",
    "    # print(\"-------\")\n",
    "    # for fff in range(0,100):\n",
    "    # print(losses[\"G\"][fff][0])\n",
    "\n",
    "\n",
    "train(d, epochs=100, plt_frq=20, BATCH_SIZE=128)\n",
    "for i in range(0,100):\n",
    "    print(losses[\"G\"][i][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
