{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (1.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pydot) (2.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "X_train reshape: (50000, 32, 32, 3)\n",
      "X_test reshape: (50000, 32, 32, 3)\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 2048)              206848    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 4, 4, 256)         3277056   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 8, 8, 128)         819328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 16, 16, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 32, 32, 3)         4803      \n",
      "=================================================================\n",
      "Total params: 4,516,739\n",
      "Trainable params: 4,514,819\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 2048)         4310144     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "generation (Dense)              (None, 1)            2049        sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "auxiliary (Dense)               (None, 11)           22539       sequential_2[1][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,334,732\n",
      "Trainable params: 4,332,940\n",
      "Non-trainable params: 1,792\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 32, 32, 3)         4516739   \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              [(None, 1), (None, 11)]   4334732   \n",
      "=================================================================\n",
      "Total params: 8,851,471\n",
      "Trainable params: 4,514,819\n",
      "Non-trainable params: 4,336,652\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "epoch 0 fid : 791.2246502077105\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fe8ceb63f0dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0myf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclassnum\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0myf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mclassnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mg_loss_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myf2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "!pip install pydot\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, LeakyReLU, BatchNormalization, ReLU\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Reshape, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras import initializers\n",
    "from keras.utils import plot_model, np_utils\n",
    "from keras import backend as K\n",
    "import scipy as sp\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "adam = Adam(lr=0.0004, beta_1=0.5)\n",
    "\n",
    "def scale_images(images, new_shape):\n",
    "    images_list = list()\n",
    "    for image in images:\n",
    "        # resize with nearest neighbor interpolation\n",
    "        new_image = np.resize(image, new_shape)\n",
    "        # store\n",
    "        images_list.append(new_image)\n",
    "    return np.asarray(images_list)\n",
    "\n",
    "\n",
    "def get_fid(act1, act2):\n",
    "    # calculate mean and covariance statistics\n",
    "    mu1, sigma1 = act1.mean(axis=0), np.cov(act1, rowvar=False)\n",
    "    mu2, sigma2 = act2.mean(axis=0), np.cov(act2, rowvar=False)\n",
    "    # calculate sum squared difference between means\n",
    "    ssdiff = np.sum((mu1 - mu2)**2.0)\n",
    "    # calculate sqrt of product between cov\n",
    "    covmean = sp.linalg.sqrtm(sigma1.dot(sigma2))\n",
    "    # check and correct imaginary numbers from sqrt\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    # calculate score\n",
    "    fid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "    return fid\n",
    "\n",
    "\n",
    "# load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 3, 32, 32)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 3, 32, 32)\n",
    "    input_shape = (3, 32, 32)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], 32, 32, 3)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 32, 32, 3)\n",
    "    input_shape = (32, 32, 3)\n",
    "\n",
    "classnum=10\n",
    "num_classes = len(np.unique(y_train))\n",
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# the generator is using tanh activation, for which we need to preprocess\n",
    "# the image data into the range between -1 and 1.\n",
    "\n",
    "X_train = np.float32(X_train)\n",
    "X_train = (X_train / 255 - 0.5) * 2\n",
    "X_train = np.clip(X_train, -1, 1)\n",
    "\n",
    "X_test = np.float32(X_test)\n",
    "X_test = (X_train / 255 - 0.5) * 2\n",
    "X_test = np.clip(X_test, -1, 1)\n",
    "\n",
    "print('X_train reshape:', X_train.shape)\n",
    "print('X_test reshape:', X_test.shape)\n",
    "\n",
    "\n",
    "# latent space dimension\n",
    "latent_dim = 100\n",
    "adam_lr = 0.0004\n",
    "adam_beta_1 = 0.5\n",
    "\n",
    "init = initializers.RandomNormal(stddev=0.02)\n",
    "\n",
    "# Generator network\n",
    "generator = Sequential()\n",
    "\n",
    "# FC: 2x2x512\n",
    "generator.add(Dense(2*2*512, input_shape=(latent_dim,), kernel_initializer=init))\n",
    "generator.add(Reshape((2, 2, 512)))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(LeakyReLU(0.2))\n",
    "\n",
    "# # Conv 1: 4x4x256\n",
    "generator.add(Conv2DTranspose(256, kernel_size=5, strides=2, padding='same'))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(LeakyReLU(0.2))\n",
    "\n",
    "# Conv 2: 8x8x128\n",
    "generator.add(Conv2DTranspose(128, kernel_size=5, strides=2, padding='same'))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(LeakyReLU(0.2))\n",
    "\n",
    "# Conv 3: 16x16x64\n",
    "generator.add(Conv2DTranspose(64, kernel_size=5, strides=2, padding='same'))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(LeakyReLU(0.2))\n",
    "\n",
    "# Conv 4: 32x32x3\n",
    "generator.add(Conv2DTranspose(3, kernel_size=5, strides=2, padding='same',\n",
    "                              activation='tanh'))\n",
    "\n",
    "generator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0004, beta_1=0.5))\n",
    "generator.summary()\n",
    "\n",
    "\n",
    "# imagem shape 32x32x3\n",
    "img_shape = X_train[0].shape\n",
    "\n",
    "# Discriminator network\n",
    "discriminator = Sequential()\n",
    "\n",
    "# Conv 1: 16x16x64\n",
    "discriminator.add(Conv2D(64, kernel_size=5, strides=2, padding='same',\n",
    "                         input_shape=(img_shape), kernel_initializer=init))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "\n",
    "# Conv 2:\n",
    "discriminator.add(Conv2D(128, kernel_size=5, strides=2, padding='same'))\n",
    "discriminator.add(BatchNormalization())\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "\n",
    "# Conv 3:\n",
    "discriminator.add(Conv2D(256, kernel_size=5, strides=2, padding='same'))\n",
    "discriminator.add(BatchNormalization())\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "\n",
    "# Conv 3:\n",
    "discriminator.add(Conv2D(512, kernel_size=5, strides=2, padding='same'))\n",
    "discriminator.add(BatchNormalization())\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "\n",
    "# FC\n",
    "discriminator.add(Flatten())\n",
    "\n",
    "# Output\n",
    "\n",
    "\n",
    "image = Input(shape=(32, 32, 3))\n",
    "\n",
    "features = discriminator(image)\n",
    "\n",
    "# first output (name=generation) is whether or not the discriminator\n",
    "    # thinks the image that is being shown is fake, and the second output\n",
    "    # (name=auxiliary) is the class that the discriminator thinks the image\n",
    "    # belongs to.\n",
    "fake = Dense(1, activation='sigmoid', name='generation')(features)\n",
    "aux = Dense(classnum+1, activation='softmax', name='auxiliary')(features)\n",
    "discriminator=Model(image, [fake, aux])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "discriminator.summary()\n",
    "\n",
    "discriminator.compile(\n",
    "        optimizer=Adam(lr=adam_lr, beta_1=adam_beta_1),\n",
    "        loss=['binary_crossentropy','categorical_crossentropy'],loss_weights=[1., 0.1])\n",
    "\n",
    "\n",
    "\n",
    "# d_g = discriminador(generador(z))\n",
    "discriminator.trainable = False\n",
    "\n",
    "inputs = Input(shape=(latent_dim, ))\n",
    "\n",
    "\n",
    "f = generator(inputs)\n",
    "\n",
    "    # we only want to be able to train generation for the combined model\n",
    "\n",
    "fake, aux = discriminator(f)\n",
    "\n",
    "gan = Model(inputs, [fake, aux])\n",
    "\n",
    "\n",
    "\n",
    "gan.compile(loss=['binary_crossentropy','categorical_crossentropy' ], optimizer=Adam(lr=0.0004, beta_1=0.5), metrics=['binary_accuracy'],loss_weights=[1., 0.1])\n",
    "\n",
    "\n",
    "plot_model(generator, to_file='cifar-g-model.png', show_shapes=True, show_layer_names=True)\n",
    "plot_model(discriminator, to_file='cifar-d-model.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "\n",
    "gan.summary()\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "smooth = 0.1\n",
    "\n",
    "\n",
    "\n",
    "d_loss = []\n",
    "g_loss = []\n",
    "\n",
    "mfid=[]\n",
    "for e in range(0,epochs + 1):\n",
    "    for i in range(len(X_train) // batch_size):\n",
    "\n",
    "        \n",
    "        \n",
    "        yr = np.zeros((batch_size))\n",
    "        yr[:batch_size] = 1\n",
    "        yr2 = np.zeros((batch_size,classnum+1))\n",
    "        yr2[:batch_size,0] = 1\n",
    "\n",
    "        yf = np.zeros((batch_size))\n",
    "        yf[:batch_size] = 0\n",
    "        yf2 = np.zeros((batch_size,classnum+1))\n",
    "        yf2[:batch_size,(e%classnum)+1] = 1\n",
    "        \n",
    "        # Train Discriminator weights\n",
    "        discriminator.trainable = True\n",
    "        \n",
    "        # Real samples\n",
    "        X_batch = X_train[i*batch_size:(i+1)*batch_size]\n",
    "        d_loss_real = discriminator.train_on_batch(x=X_batch,\n",
    "                                                   y=[yr,yr2])\n",
    "        \n",
    "        # Fake Samples\n",
    "        z = np.random.normal(loc=0, scale=1, size=(batch_size, latent_dim))\n",
    "        X_fake = generator.predict_on_batch(z)\n",
    "        d_loss_fake = discriminator.train_on_batch(x=X_fake, y=[yf,yf2])\n",
    "         \n",
    "        # Discriminator loss\n",
    "        d_loss_batch = 0.5 * (d_loss_real[0] + d_loss_fake[0])\n",
    "        \n",
    "        # Train Generator weights\n",
    "        discriminator.trainable = False\n",
    "        yf2 = np.zeros((batch_size,classnum+1))\n",
    "        yf2[:batch_size,(e%classnum)+1] = 1\n",
    "        g_loss_batch = gan.train_on_batch(x=z, y=[yr,yf2])\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "       # print(\n",
    "            #'epoch = %d/%d, batch = %d/%d, d_loss=%.3f, g_loss=%.3f' % (e + 1, epochs, i, len(X_train) // batch_size, d_loss_batch, g_loss_batch),\n",
    "            #100*' ',\n",
    "            #end='\\r'\n",
    "        #)\n",
    "\n",
    "\n",
    "    #model = InceptionV3(include_top=False, pooling='avg', input_shape=(299,299,3))\n",
    "    #images1 = scale_images(X_batch, (299,299,3))\n",
    "    #images2 = scale_images(X_fake, (299,299,3))\n",
    "    #images1 = preprocess_input(images1)\n",
    "    #images2 = preprocess_input(images2)\n",
    "    #act1 = model.predict(images1)\n",
    "    #act2 = model.predict(images2)\n",
    "\n",
    "    act1 = X_batch.reshape(batch_size,3072 )\n",
    "    act2 = X_fake.reshape(batch_size,3072 )\n",
    "    temp=get_fid(act1, act2)\n",
    "    print('epoch ' + str(e)+' fid : ' + str(temp))\n",
    "    \n",
    "    mfid.append(temp)\n",
    "    #d_loss.append(d_loss)\n",
    "    #g_loss.append(g_loss[0])\n",
    "    #print('epoch = %d/%d, d_loss=%.3f, g_loss=%.3f' % (e + 1, epochs, d_loss[-1], g_loss[-1]), 100*' ')\n",
    "\n",
    "    if e % 2 == 0:\n",
    "        samples = 10\n",
    "        x_fake = generator.predict(np.random.normal(loc=0, scale=1, size=(samples, latent_dim)))\n",
    "\n",
    "        for k in range(samples):\n",
    "            plt.subplot(2, 5, k + 1, xticks=[], yticks=[])\n",
    "            plt.imshow(((x_fake[k] + 1)* 127).astype(np.uint8))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        #plt.show()\n",
    "    \n",
    "\n",
    "for i in range(0,100):\n",
    "    print(mfid[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
