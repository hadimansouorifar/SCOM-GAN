{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 5us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 4s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 1s 0us/step\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:100: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3920, kernel_initializer=\"glorot_normal\")`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:105: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3920)              395920    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 3920)              15680     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3920)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 20, 14, 14)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 40, 28, 14)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 40, 28, 10)        1270      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 40, 28, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 40, 28, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 40, 28, 5)         455       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 40, 28, 5)         20        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 40, 28, 5)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 40, 28, 1)         6         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 40, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 413,391\n",
      "Trainable params: 405,521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(5, (3, 3), padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:111: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (1, 1), padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-trainable params: 7,870\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 5488)              554288    \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 7, 7, 112)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 7, 7, 112)         448       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 7, 7, 112)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 56)        156856    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 14, 14, 56)        224       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 14, 14, 56)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 1)         1401      \n",
      "=================================================================\n",
      "Total params: 713,217\n",
      "Trainable params: 712,881\n",
      "Non-trainable params: 336\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 56)        1456      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 112)         156912    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 224)         627424    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3584)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 112)               401520    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 113       \n",
      "=================================================================\n",
      "Total params: 1,187,425\n",
      "Trainable params: 1,187,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 28, 28, 1)         713221    \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 1)                 1187425   \n",
      "=================================================================\n",
      "Total params: 1,900,646\n",
      "Trainable params: 712,883\n",
      "Non-trainable params: 1,187,763\n",
      "_________________________________________________________________\n",
      "Epochs: 100\n",
      "Batch size: 128\n",
      "Batches per epoch: 234\n",
      "--------------- Epoch 1 ---------------\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "fid : 199.99079255901583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 4800x800 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fid : 49.31038147388017\n",
      "fid : 140.48658177101356\n",
      "fid : 96.24495645962845\n",
      "fid : 55.54836869271897\n",
      "fid : 61.49900624756225\n",
      "fid : 66.254260241344\n",
      "fid : 64.45300340998041\n",
      "fid : 54.313497471332056\n",
      "fid : 53.57552667361824\n",
      "fid : 52.66769545470994\n",
      "fid : 42.376474924075\n",
      "fid : 55.32951858606829\n",
      "fid : 51.17456551515933\n",
      "fid : 44.51603941235621\n",
      "fid : 44.6562383670644\n",
      "fid : 43.816391818020655\n",
      "fid : 46.645549996089485\n",
      "fid : 47.6680757621728\n",
      "--------------- Epoch 20 ---------------\n",
      "fid : 42.74172222389394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 4800x800 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fid : 40.5924203641096\n",
      "fid : 41.415494282729625\n",
      "fid : 48.04118439104018\n",
      "fid : 34.44761627721383\n",
      "fid : 41.63747712204555\n",
      "fid : 35.850189981227544\n",
      "fid : 33.61948357412486\n",
      "fid : 30.674172949744985\n",
      "fid : 42.78381455536145\n",
      "fid : 35.994330558296156\n",
      "fid : 41.24999967302827\n",
      "fid : 34.32275786191274\n",
      "fid : 35.99559749248266\n",
      "fid : 35.06223530165145\n",
      "fid : 37.476567022218504\n",
      "fid : 36.729341860975595\n",
      "fid : 35.101209040977196\n",
      "fid : 34.49942306853445\n",
      "fid : 35.96304740648869\n",
      "--------------- Epoch 40 ---------------\n",
      "fid : 35.80706583743792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 4800x800 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fid : 41.29266724817629\n",
      "fid : 37.980734095891904\n",
      "fid : 39.5242469104663\n",
      "fid : 36.3070589146526\n",
      "fid : 40.23440328351998\n",
      "fid : 41.149862155418035\n",
      "fid : 44.0691734365004\n",
      "fid : 35.817870610050434\n",
      "fid : 39.82277340986011\n",
      "fid : 41.01447209119928\n",
      "fid : 43.020695296260456\n",
      "fid : 38.014468175361166\n",
      "fid : 42.97671593502019\n",
      "fid : 42.81808085746128\n",
      "fid : 39.22385955436455\n",
      "fid : 39.03927885063421\n",
      "fid : 39.135212523973856\n",
      "fid : 43.64437281451253\n",
      "fid : 39.42083832306416\n",
      "--------------- Epoch 60 ---------------\n",
      "fid : 39.26793374125565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 4800x800 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fid : 44.72814304826577\n",
      "fid : 44.908020039606754\n",
      "fid : 42.32088798543617\n",
      "fid : 40.78883185586869\n",
      "fid : 44.86624906211728\n",
      "fid : 39.13181284990338\n",
      "fid : 41.625184094251395\n",
      "fid : 45.821278123056224\n",
      "fid : 44.20087578043598\n",
      "fid : 35.39398127309944\n",
      "fid : 43.04230991157223\n",
      "fid : 40.97321921942543\n",
      "fid : 46.18694572848896\n",
      "fid : 45.06152214322722\n",
      "fid : 44.63014932409471\n",
      "fid : 44.72835849132589\n",
      "fid : 37.95373148534946\n",
      "fid : 42.27449105849755\n",
      "fid : 43.11147985917445\n",
      "--------------- Epoch 80 ---------------\n",
      "fid : 47.85596774757954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 4800x800 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fid : 49.583527222581296\n",
      "fid : 40.470584349181465\n",
      "fid : 46.16010215407023\n",
      "fid : 49.57121012473803\n",
      "fid : 45.00366370314353\n",
      "fid : 40.44852880352418\n",
      "fid : 45.12050187841143\n",
      "fid : 44.378789858220955\n",
      "fid : 45.13547140693012\n",
      "fid : 41.391197874513225\n",
      "fid : 36.07813522803848\n",
      "fid : 43.09047566258446\n",
      "fid : 41.96968040522806\n",
      "fid : 40.40367915452603\n",
      "fid : 44.233731357022734\n",
      "fid : 40.07388536674739\n",
      "fid : 47.48998285285841\n",
      "fid : 47.181223180990486\n",
      "fid : 46.207284924957165\n",
      "--------------- Epoch 100 ---------------\n",
      "fid : 46.46744868399938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 4800x800 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199.99079255901583\n",
      "49.31038147388017\n",
      "140.48658177101356\n",
      "96.24495645962845\n",
      "55.54836869271897\n",
      "61.49900624756225\n",
      "66.254260241344\n",
      "64.45300340998041\n",
      "54.313497471332056\n",
      "53.57552667361824\n",
      "52.66769545470994\n",
      "42.376474924075\n",
      "55.32951858606829\n",
      "51.17456551515933\n",
      "44.51603941235621\n",
      "44.6562383670644\n",
      "43.816391818020655\n",
      "46.645549996089485\n",
      "47.6680757621728\n",
      "42.74172222389394\n",
      "40.5924203641096\n",
      "41.415494282729625\n",
      "48.04118439104018\n",
      "34.44761627721383\n",
      "41.63747712204555\n",
      "35.850189981227544\n",
      "33.61948357412486\n",
      "30.674172949744985\n",
      "42.78381455536145\n",
      "35.994330558296156\n",
      "41.24999967302827\n",
      "34.32275786191274\n",
      "35.99559749248266\n",
      "35.06223530165145\n",
      "37.476567022218504\n",
      "36.729341860975595\n",
      "35.101209040977196\n",
      "34.49942306853445\n",
      "35.96304740648869\n",
      "35.80706583743792\n",
      "41.29266724817629\n",
      "37.980734095891904\n",
      "39.5242469104663\n",
      "36.3070589146526\n",
      "40.23440328351998\n",
      "41.149862155418035\n",
      "44.0691734365004\n",
      "35.817870610050434\n",
      "39.82277340986011\n",
      "41.01447209119928\n",
      "43.020695296260456\n",
      "38.014468175361166\n",
      "42.97671593502019\n",
      "42.81808085746128\n",
      "39.22385955436455\n",
      "39.03927885063421\n",
      "39.135212523973856\n",
      "43.64437281451253\n",
      "39.42083832306416\n",
      "39.26793374125565\n",
      "44.72814304826577\n",
      "44.908020039606754\n",
      "42.32088798543617\n",
      "40.78883185586869\n",
      "44.86624906211728\n",
      "39.13181284990338\n",
      "41.625184094251395\n",
      "45.821278123056224\n",
      "44.20087578043598\n",
      "35.39398127309944\n",
      "43.04230991157223\n",
      "40.97321921942543\n",
      "46.18694572848896\n",
      "45.06152214322722\n",
      "44.63014932409471\n",
      "44.72835849132589\n",
      "37.95373148534946\n",
      "42.27449105849755\n",
      "43.11147985917445\n",
      "47.85596774757954\n",
      "49.583527222581296\n",
      "40.470584349181465\n",
      "46.16010215407023\n",
      "49.57121012473803\n",
      "45.00366370314353\n",
      "40.44852880352418\n",
      "45.12050187841143\n",
      "44.378789858220955\n",
      "45.13547140693012\n",
      "41.391197874513225\n",
      "36.07813522803848\n",
      "43.09047566258446\n",
      "41.96968040522806\n",
      "40.40367915452603\n",
      "44.233731357022734\n",
      "40.07388536674739\n",
      "47.48998285285841\n",
      "47.181223180990486\n",
      "46.207284924957165\n",
      "46.46744868399938\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Activation, Flatten, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose, UpSampling2D, Convolution2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt2\n",
    "import random\n",
    "#from tqdm import tqdm_notebook\n",
    "import math\n",
    "from keras import layers\n",
    "\n",
    "import scipy as sp\n",
    "#from tqdm import tqdm_notebook\n",
    "from math import floor\n",
    "from numpy import ones\n",
    "from numpy import expand_dims\n",
    "from numpy import log\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import exp\n",
    "from numpy import resize\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    " \n",
    "# assumes images have the shape 299x299x3, pixels in [0,255]\n",
    "def scale_images(images, new_shape):\n",
    "    images_list = list()\n",
    "    for image in images:\n",
    "        # resize with nearest neighbor interpolation\n",
    "        new_image = resize(image, new_shape)\n",
    "        # store\n",
    "        images_list.append(new_image)\n",
    "    return np.asarray(images_list)\n",
    "def calculate_inception_score(images, n_split=10, eps=1E-16):\n",
    "    # load inception v3 model\n",
    "    model = InceptionV3()\n",
    "    # convert from uint8 to float32\n",
    "    processed = images.astype('float32')\n",
    "    # pre-process raw images for inception v3 model\n",
    "    processed = preprocess_input(processed)\n",
    "    # predict class probabilities for images\n",
    "    yhat = model.predict(processed)\n",
    "    # enumerate splits of images/predictions\n",
    "    scores = list()\n",
    "    n_part = floor(images.shape[0] / n_split)\n",
    "    for i in range(n_split):\n",
    "        # retrieve p(y|x)\n",
    "        ix_start, ix_end = i * n_part, i * n_part + n_part\n",
    "        p_yx = yhat[ix_start:ix_end]\n",
    "        # calculate p(y)\n",
    "        p_y = expand_dims(p_yx.mean(axis=0), 0)\n",
    "        # calculate KL divergence using log probabilities\n",
    "        kl_d = p_yx * (log(p_yx + eps) - log(p_y + eps))\n",
    "        # sum over classes\n",
    "        sum_kl_d = kl_d.sum(axis=1)\n",
    "        # average over images\n",
    "        avg_kl_d = mean(sum_kl_d)\n",
    "        # undo the log\n",
    "        is_score = exp(avg_kl_d)\n",
    "        # store\n",
    "        scores.append(is_score)\n",
    "    # average across images\n",
    "    is_avg, is_std = mean(scores), std(scores)\n",
    "    return is_avg, is_std\n",
    "# calculate frechet inception distance\n",
    "def get_fid(act1, act2):\n",
    "    # calculate mean and covariance statistics\n",
    "    mu1, sigma1 = act1.mean(axis=0), np.cov(act1, rowvar=False)\n",
    "    mu2, sigma2 = act2.mean(axis=0), np.cov(act2, rowvar=False)\n",
    "    # calculate sum squared difference between means\n",
    "    ssdiff = np.sum((mu1 - mu2)**2.0)\n",
    "    # calculate sqrt of product between cov\n",
    "    covmean = sp.linalg.sqrtm(sigma1.dot(sigma2))\n",
    "    # check and correct imaginary numbers from sqrt\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    # calculate score\n",
    "    fid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "    return fid\n",
    "# Dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images.\n",
    "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()\n",
    "# print(X_train.shape)\n",
    "\n",
    "z_dim = 100\n",
    "\n",
    "X_train = X_train.reshape(60000, 28, 28, 1)\n",
    "X_test = X_test.reshape(10000, 28, 28, 1)\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "X_train = X_train[0:30000]\n",
    "\n",
    "nch = 20\n",
    "g_input = Input(shape=[100])\n",
    "H1 = Dense(nch * 14 * 14, init='glorot_normal')(g_input)\n",
    "H = BatchNormalization()(H1)\n",
    "H = Activation('relu')(H)\n",
    "H = Reshape([nch, 14, 14])(H)\n",
    "H = UpSampling2D(size=(2, 2))(H)\n",
    "H = Convolution2D(int(nch / 2), 3, 3, border_mode='same', init='glorot_uniform')(H)\n",
    "H = BatchNormalization()(H)\n",
    "H = Activation('relu')(H)\n",
    "H = Convolution2D(int(nch / 4), 3, 3, border_mode='same', init='glorot_uniform')(H)\n",
    "H = BatchNormalization()(H)\n",
    "H = Activation('relu')(H)\n",
    "H = Convolution2D(1, 1, 1, border_mode='same', init='glorot_uniform')(H)\n",
    "g_V = Activation('sigmoid')(H)\n",
    "generator = Model(g_input, g_V)\n",
    "generator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
    "generator.summary()\n",
    "\n",
    "# Generator\n",
    "adam = Adam(lr=0.0002, beta_1=0.5)\n",
    "\n",
    "g = Sequential()\n",
    "layer = g.add(Dense(7 * 7 * 112, input_dim=z_dim))\n",
    "g.add(Reshape((7, 7, 112)))\n",
    "g.add(BatchNormalization())\n",
    "g.add(Activation(LeakyReLU(alpha=0.2)))\n",
    "g.add(Conv2DTranspose(56, 5, strides=2, padding='same'))\n",
    "g.add(BatchNormalization())\n",
    "g.add(Activation(LeakyReLU(alpha=0.2)))\n",
    "g.add(Conv2DTranspose(1, 5, strides=2, padding='same', activation='sigmoid'))\n",
    "g.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "g.summary()\n",
    "\n",
    "d = Sequential()\n",
    "d.add(Conv2D(56, 5, strides=2, padding='same', input_shape=(28, 28, 1), activation=LeakyReLU(alpha=0.2)))\n",
    "d.add(Conv2D(112, 5, strides=2, padding='same'))\n",
    "g.add(BatchNormalization())\n",
    "g.add(Activation(LeakyReLU(alpha=0.2)))\n",
    "d.add(Conv2D(224, 5, strides=2, padding='same'))\n",
    "g.add(Activation(LeakyReLU(alpha=0.2)))\n",
    "d.add(Flatten())\n",
    "d.add(Dense(112, activation=LeakyReLU(alpha=0.2)))\n",
    "d.add(Dense(1, activation='sigmoid'))\n",
    "d.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "d.summary()\n",
    "\n",
    "d.trainable = False\n",
    "inputs = Input(shape=(z_dim,))\n",
    "hidden = g(inputs)\n",
    "output = d(hidden)\n",
    "gan = Model(inputs, output)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "gan.summary()\n",
    "\n",
    "\n",
    "def plot_loss(losses):\n",
    "    \"\"\"\n",
    "    @losses.keys():\n",
    "        0: loss\n",
    "        1: accuracy\n",
    "    \"\"\"\n",
    "    d_loss = [v[0] for v in losses[\"D\"]]\n",
    "    g_loss = [v[0] for v in losses[\"G\"]]\n",
    "\n",
    "    plt.figure(figsize=(6.4, 4.8))\n",
    "    plt.plot(d_loss, color='red', label=\"Discriminator loss\")\n",
    "    plt.plot(g_loss, color='green', label=\"Generator loss\")\n",
    "    plt.title(\"GAN : MNIST dataset\")\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('loss.png')\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "def plot_generated(n_ex=20, dim=(2, 10), figsize=(48, 8)):\n",
    "    noise = np.random.normal(0, 1, size=(n_ex, z_dim))\n",
    "    generated_images = g.predict(noise)\n",
    "    generated_images = generated_images.reshape(generated_images.shape[0], 28, 28)\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i + 1)\n",
    "        # plt.imshow(generated_images[i, :, :], interpolation='nearest', cmap='gray_r')\n",
    "        sss = str(i)\n",
    "\n",
    "        plt.imsave(sss, generated_images[i, :, :], cmap='gray_r')\n",
    "\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.plot()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Set up a vector (dict) to store the losses\n",
    "losses = {\"D\": [], \"G\": []}\n",
    "samples = []\n",
    "\n",
    "\n",
    "mfid=[]\n",
    "def train(d, epochs=1, plt_frq=1, BATCH_SIZE=128):\n",
    "    batchCount = int(X_train.shape[0] / BATCH_SIZE)\n",
    "    #batchCount=100\n",
    "    print('Epochs:', epochs)\n",
    "    print('Batch size:', BATCH_SIZE)\n",
    "    print('Batches per epoch:', batchCount)\n",
    "\n",
    "    d_v = []\n",
    "    for e in range(1, epochs + 1):\n",
    "        if e == 1 or e % plt_frq == 0:\n",
    "            print('-' * 15, 'Epoch %d' % e, '-' * 15)\n",
    "        for _ in range(batchCount):  # tqdm_notebook(range(batchCount), leave=False):\n",
    "            # Create a batch by drawing random index numbers from the training set\n",
    "            image_batch = X_train[np.random.randint(0, X_train.shape[0], size=BATCH_SIZE)]\n",
    "            image_batch = image_batch.reshape(image_batch.shape[0], image_batch.shape[1], image_batch.shape[2], 1)\n",
    "            # print(image_batch.shape)\n",
    "            # Create noise vectors for the generator\n",
    "            noise = np.random.normal(0, 1, size=(BATCH_SIZE, z_dim))\n",
    "\n",
    "            # Generate the images from the noise\n",
    "            generated_images = g.predict(noise)\n",
    "            samples.append(generated_images)\n",
    "            X = np.concatenate((image_batch, generated_images))\n",
    "            # Create labels\n",
    "            y = np.zeros(2 * BATCH_SIZE)\n",
    "            y[:BATCH_SIZE] = 0.9  # One-sided label smoothing\n",
    "\n",
    "            # Train discriminator on generated images\n",
    "            d.trainable = True\n",
    "            d_loss = d.train_on_batch(X, y)\n",
    "            # Train generator\n",
    "            noise = np.random.normal(0, 1, size=(BATCH_SIZE, z_dim))\n",
    "            y2 = np.ones(BATCH_SIZE)\n",
    "            d.trainable = False\n",
    "            g_loss = gan.train_on_batch(noise, y2)\n",
    "            weights = []\n",
    "            ccc = 0\n",
    "\n",
    "        #weights = g.layers[0].get_weights()[0]\n",
    "        #w = 3\n",
    "        #weights = weights.reshape(548800)\n",
    "        #bin = [-0.08, -0.06, -0.04, -0.02, 0, 0.02, 0.04, 0.06, 0.08]\n",
    "\n",
    "        #px,py,_ = plt2.hist(weights, bins=100)\n",
    "        #print(str(np.argmax(px)) + '--' + str(np.max(py)))\n",
    "\n",
    "        sss = str(e)\n",
    "        # plt2.savefig(\"plt\" +sss +\".png\")\n",
    "        # plt2.clf()\n",
    "        #print(len(weights))\n",
    "\n",
    "        # Only store losses from final batch of epoch\n",
    "        #images1 = scale_images(generated_images, (299,299,3))\n",
    "        #print(calculate_inception_score(images1))\n",
    "        \n",
    "        \n",
    "        image_batch = image_batch.reshape(BATCH_SIZE,784)\n",
    "        generated_images = generated_images.reshape(BATCH_SIZE,784)\n",
    "        temp=get_fid(generated_images, image_batch)\n",
    "        print('fid : ' + str(temp))\n",
    "        \n",
    "        mfid.append(temp)\n",
    "        losses[\"D\"].append(d_loss)\n",
    "        losses[\"G\"].append(g_loss)\n",
    "\n",
    "        # Update the plots\n",
    "        if e == 1 or e % plt_frq == 0:\n",
    "            plot_generated()\n",
    "    # print((weights.shape ))\n",
    "    \n",
    "\n",
    "    # for fff in range(0,100):\n",
    "    # print(losses[\"D\"][fff][0])\n",
    "    # print(\"-------\")\n",
    "    # for fff in range(0,100):\n",
    "    # print(losses[\"G\"][fff][0])\n",
    "\n",
    "\n",
    "train(d, epochs=100, plt_frq=20, BATCH_SIZE=128)\n",
    "\n",
    "for i in range(0,100):\n",
    "    print(mfid[i])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
